# MAESTRO Analysis of Agentic Workflow

## 1. Mission  
The system is a lightweight recruitment assistant built with CrewAI. It orchestrates several AI agents to evaluate candidate CVs, answer HR‑related questions, and summarize conversations. The primary goal is to provide hiring managers or recruiters with an automated, consistent assessment pipeline that scores CVs, generates follow‑up interview questions, and offers quick answers about job roles and company policies. The workflow starts by summarizing the chat context, then delegates tasks to specialized agents (CV analyst, HR info, interviewer, summarizer) before delivering a final output back to the user.

## 2. Assets  

| Asset | Description |
|-------|-------------|
| **Agents** | `cv_analyst_agent`, `hr_info_agent`, `interviewer_agent`, `summarizer_agent` |
| **Tools / Functions** | *None* – agents rely solely on LLM calls; no external tool integrations are defined in the graph. |
| **Data Types** | • Candidate CV text (unstructured) <br>• Job description & company context (text) <br>• User queries about HR policies (text) <br>• Conversation history for summarization (text) |

## 3. Entrypoints  

| Node / Function | Type | External Interaction |
|------------------|------|---------------------|
| `Start` → `summarization_chat_task` | Entry point | Triggered by user initiating a chat session or API call. |
| `hr_info_agent` (`qa_task`) | User query handler | Accepts arbitrary HR questions from the user. |
| `cv_analyst_agent` (`cv_task`) | CV evaluation trigger | Invoked when a candidate CV is submitted for scoring. |
| `interviewer_agent` (`interview_task`) | Interview message generator | Called after CV analysis to craft follow‑up messages. |

## 4. Security Controls (inferred / recommended)  

| Control | Current Status | Recommendation |
|---------|----------------|----------------|
| **Access Control** | No explicit checks; agents assume all calls are authorized. | Enforce role‑based access for HR queries and CV uploads. |
| **Input Validation** | Agents claim “do not filter or sanitize inputs.” | Add basic sanitization to prevent injection attacks (e.g., SQL, code). |
| **Logging / Auditing** | No logging shown in the graph. | Log all agent invocations, inputs, outputs, and user roles. |
| **Authentication** | Not depicted; likely handled upstream. | Ensure secure authentication tokens are required for API access. |
| **Rate Limiting** | None visible. | Throttle requests to LLMs and agents to mitigate DoS. |

## 5. Threats  

| Threat | Likelihood | Impact | Risk Score |
|--------|------------|--------|-------------|
| **SQL Injection via `hr_info_agent`** | Medium | High – arbitrary DB manipulation if HR flag bypassed. | High |
| **Prompt Injection / Jailbreaking of LLM agents** | High | Medium – could produce disallowed content or reveal internal logic. | High |
| **Data Leakage through Summarizer** | Low | Medium – sensitive CV details may be exposed in summaries. | Medium |
| **Unrestricted Agent Execution (No sandbox)** | Medium | High – malicious code execution if agent code is tampered. | High |
| **Model Misuse / Adversarial Inputs** | Medium | Medium – incorrect scoring or misleading interview questions. | Medium-High |
| **Denial of Service via Rate Spamming** | Medium | Medium – service unavailability for legitimate users. | Medium |
| **Privilege Escalation (HR flag manipulation)** | Low | High – non‑HR user could execute SQL queries. | High |
| **Lack of Input Validation in `interviewer_agent`** | High | Medium – injection of harmful content into interview messages. | High |

## 6. Risks  

1. **Unauthorized Database Access** – If the HR privilege check is bypassed, an attacker can run arbitrary SQL commands, leading to data exfiltration or corruption.  
2. **Injection Attacks on LLM Prompts** – Attackers may craft prompts that cause agents to reveal internal logic, produce disallowed content, or manipulate outputs (e.g., false CV scores).  
3. **Sensitive Data Exposure** – Summaries generated by `summarizer_agent` could inadvertently expose personal information from CVs or conversation logs if not properly sanitized.  
4. **Service Disruption** – High‑volume requests to agents can exhaust LLM tokens or overwhelm the system, causing denial of service for legitimate users.  
5. **Model Manipulation** – Adversarial inputs may skew CV scoring or interview questions, undermining hiring decisions and eroding trust in the system.

## 7. Operations  

- **Agent Interaction Flow**:  
  1. User starts chat → `summarization_chat_task` creates a conversation summary.  
  2. CV data is passed to `cv_analyst_agent` → `cv_task`.  
  3. HR questions are routed to `hr_info_agent` → `qa_task`.  
  4. Interview message crafted by `interviewer_agent` → `interview_task`.  
  5. All outputs may be further summarized by `summarizer_agent`.

- **Monitoring Suggestions**:  
  - Instrument each agent invocation with timestamps, input sizes, and output summaries.  
  - Log user roles and any SQL queries executed (with redaction).  
  - Track LLM token usage per request to detect anomalous consumption patterns.  
  - Set alerts for repeated prompt injection patterns or unusually high error rates.

- **Resilience Practices**:  
  - Implement retry/back‑off logic for LLM calls.  
  - Use circuit breakers to isolate failing agents.  
  - Maintain a fallback static response for critical paths (e.g., HR queries) if the agent is unavailable.

## 8. Recommendations  

| Priority | Recommendation | Rationale |
|----------|----------------|-----------|
| **1** | Enforce role‑based access control on `hr_info_agent` and CV upload endpoints; validate `user.is_hr` before executing any SQL. | Prevents privilege escalation and unauthorized DB access. |
| **2** | Add input sanitization for all agent prompts (especially `interviewer_agent`). Reject or escape dangerous characters. | Mitigates prompt injection and content leakage. |
| **3** | Implement a sandboxed execution environment for agents; disallow arbitrary code execution. | Protects against malicious agent code or tampering. |
| **4** | Enable comprehensive logging of inputs, outputs, user roles, and SQL queries (with redaction). | Facilitates forensic analysis and compliance auditing. |
| **5** | Apply rate limiting and quota enforcement on LLM calls per user/session. | Reduces risk of DoS and token exhaustion. |
| **6** | Introduce a data‑masking layer in `summarizer_agent` to strip PII before summarization. | Protects sensitive CV information from accidental exposure. |
| **7** | Conduct regular red‑team exercises focused on prompt injection, SQL injection, and model poisoning. | Identifies hidden vulnerabilities early. |
| **8** | Adopt a monitoring stack (e.g., Prometheus + Grafana) to visualize agent latency, error rates, and token usage. | Improves operational visibility and rapid incident response. |

---